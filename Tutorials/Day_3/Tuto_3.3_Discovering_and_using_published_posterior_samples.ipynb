{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "editable": true,
        "id": "quA5zQqJ3DkE",
        "tags": []
      },
      "source": [
        "<span style=\"float: left;padding: 1.3em\">![logo](https://github.com/gw-odw/odw/blob/main/Tutorials/logo.png?raw=1)</span>\n",
        "\n",
        "# Gravitational Wave Open Data Workshop\n",
        "\n",
        "## Tutorial 3.3: Discovering and using published posterior samples\n",
        "\n",
        "This is a simple demonstration to loading and viewing data released in associaton with the publication titled __GWTC-1: A Gravitational-Wave Transient Catalog of Compact Binary Mergers Observed by LIGO and Virgo during the First and Second Observing Runs__ available through [DCC](https://dcc.ligo.org/LIGO-P1800307/public) and [arXiv](https://arxiv.org/abs/1811.12907). This should lead to discussion and interpretation.\n",
        "\n",
        "The data used in these tutorials will be downloaded from the public DCC page [LIGO-P1800370](https://dcc.ligo.org/LIGO-P1800370/public).\n",
        "\n",
        "View this tutorial on [Google Colaboratory](https://colab.research.google.com/github/gw-odw/odw/blob/main/Tutorials/Day_3/Tuto_3.3_Discovering_and_using_published_posterior_samples.ipynb) or launch [mybinder](https://mybinder.org/v2/gh/gw-odw/odw/HEAD)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "editable": true,
        "id": "taEFmvys3DkG",
        "tags": []
      },
      "source": [
        "## Installation (execute only if running on a cloud platform, like Google Colab, or if you haven't done the installation already!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "editable": true,
        "id": "qrBuraTe3DkK",
        "tags": []
      },
      "source": [
        "> ⚠️ **Warning**: restart the runtime after running the cell below.\n",
        ">\n",
        "> To do so, click \"Runtime\" in the menu and choose \"Restart and run all\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "Collapsed": "false",
        "editable": true,
        "id": "Z2fAXT1v3DkH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# -- Use the following line for google colab removing the hash at the beginning.\n",
        "! pip install -U -q 'corner==2.2.3' 'bilby==2.4.0' 'astropy==7.0.1' 'scipy==1.12.0' 'numpy==1.25.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "6uLsysdP3DkL"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "DiR88NzK3DkM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# The first import of matplotlib can take some time (especially on cloud platforms). This is normal.\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import corner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "iBZpF7363DkO"
      },
      "source": [
        "## Get the data\n",
        "\n",
        "We first have to select the event. Let's pick GW150914!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "sPBQg9cA3DkO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "label = 'GW150914'\n",
        "\n",
        "# if you do not have wget installed, simply download manually\n",
        "# https://dcc.ligo.org/LIGO-P1800370/public/GW150914_GWTC-1.hdf5\n",
        "# from your browser\n",
        "# Learn more about this dataset here: https://dcc.ligo.org/LIGO-P1800370/public\n",
        "! wget --no-verbose https://dcc.ligo.org/LIGO-P1800370/public/{label}_GWTC-1.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "LlIkUSXc3DkR",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#If you download the file manually, you may need to move the downloaded file to the correct foalder or substitute './' with the correct path\n",
        "posterior_file = './'+label+'_GWTC-1.hdf5'\n",
        "posterior = h5py.File(posterior_file, 'r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "AyfL5UYJ3DkU"
      },
      "source": [
        "### Looking into the file structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "tgzznwnT3DkV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print('This file contains four datasets: ',posterior.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "bObo647S3DkY"
      },
      "source": [
        "This data file contains several datasets, two using separate models for the gravitational waveform (`IMRPhenomPv2` and `SEOBNRv3` respectively, see the [paper](https://arxiv.org/abs/1811.12907) for more details).\n",
        "\n",
        "It also contains a joint dataset, combining equal numbers of samples from each individual model, these datasets are what is shown in the [paper](https://arxiv.org/abs/1811.12907).\n",
        "\n",
        "Finally, there is a dataset containing samples drawn from the prior used for the analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "D12e3TRs3DkZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(posterior['Overall_posterior'].dtype.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "bM94W-lv3Dkb"
      },
      "source": [
        "Here are some brief descriptions of these parameters and their units:\n",
        "\n",
        " * `luminosity_distance_Mpc`: luminosity distance [Mpc]\n",
        "\n",
        " * `m1_detector_frame_Msun`: primary (larger) black hole mass (detector frame) [solar mass]\n",
        "\n",
        " * `m2_detector_frame_Msun`: secondary (smaller) black hole mass (detector frame) [solar mass]\n",
        "\n",
        " * `right_ascension`, `declination`: right ascension and declination of the source [rad].\n",
        "\n",
        " * `costheta_jn`: cosine of the angle between line of sight and total angular momentum vector of the system.\n",
        "\n",
        " * `spin1`, `costilt1`: primary (larger) black hole spin magnitude (dimensionless) and cosine of the zenith angle between the spin and the orbital angular momentum vector of the system.\n",
        "\n",
        " * `spin2`, `costilt2`: secondary (smaller) black hole spin magnitude (dimensionless) and cosine of the zenith angle between the spin and the orbital angular momentum vector of the system.\n",
        "\n",
        "A convenient (and pretty) way to load up this array of samples is to use [pandas](https://pandas.pydata.org/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "su0I7kOC3Dkc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "samples=pd.DataFrame.from_records(np.array(posterior['Overall_posterior']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "j_FO94bB3Dke",
        "tags": []
      },
      "outputs": [],
      "source": [
        "samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "cIAbUy1q3Dkh"
      },
      "source": [
        "Those are all the samples stored in the `Overall` dataset.\n",
        "\n",
        "### Plotting\n",
        "\n",
        "We can plot all of them with, for instance, the [corner](https://corner.readthedocs.io/en/latest/) package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "NvG83vQo3Dkh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "corner.corner(samples.values,labels=['costhetajn',\n",
        "                                'distance [Mpc]',\n",
        "                                'ra',\n",
        "                                'dec',\n",
        "                                'mass1 [Msun]',\n",
        "                                'mass2 [Msun]',\n",
        "                                'spin1',\n",
        "                                'spin2',\n",
        "                                'costilt1',\n",
        "                                'costilt2']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "GglaDuCk3Dkk"
      },
      "source": [
        "Each one and two dimensional histogram is a *marginalized* probability density function. We can manually select one parameter, say `luminosity distance`, and plot the four different marginalized distributions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "0ao_u80H3Dkl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.hist(posterior['prior']['luminosity_distance_Mpc'], bins = 100, label='prior', alpha=0.8, density=True)\n",
        "plt.hist(posterior['IMRPhenomPv2_posterior']['luminosity_distance_Mpc'], bins = 100, label='IMRPhenomPv2 posterior', alpha=0.8, density=True)\n",
        "plt.hist(posterior['SEOBNRv3_posterior']['luminosity_distance_Mpc'], bins = 100, label='SEOBNRv3 posterior', alpha=0.8, density=True)\n",
        "plt.hist(posterior['Overall_posterior']['luminosity_distance_Mpc'], bins = 100, label='Overall posterior', alpha=0.8, density=True)\n",
        "plt.xlabel(r'$D_L (Mpc)$')\n",
        "plt.ylabel('Probability Density Function')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "6u5Ba3v53Dkr"
      },
      "source": [
        "### Computing new quantities\n",
        "\n",
        "The masses given are the ones measured at the detector, i.e. in the *detector frame*. To get the actual (*source frame*) masses of the source black holes, we need to correct for the cosmological redshift of the gravitational wave. This forces us to assume a cosmological model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "hG06jTn53Dkr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import astropy.units as u\n",
        "from astropy.cosmology import Planck15, z_at_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "lv1EoAny3Dku"
      },
      "source": [
        "We now compute the redshift value for all the samples (using only the distance value). See [astropy.cosmology](https://docs.astropy.org/en/stable/api/astropy.cosmology.z_at_value.html) for implementation details, in particular how to make the following more efficient:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "RS7AD2dX3Dkv",
        "tags": []
      },
      "outputs": [],
      "source": [
        "z = np.array([z_at_value(Planck15.luminosity_distance, dist * u.Mpc) for dist in samples['luminosity_distance_Mpc']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "29S-5y-k3Dkx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "samples['m1_source_frame_Msun']=samples['m1_detector_frame_Msun']/(1.0+z)\n",
        "samples['m2_source_frame_Msun']=samples['m2_detector_frame_Msun']/(1.0+z)\n",
        "samples['redshift']=z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "lNM077Db3Dk0"
      },
      "source": [
        "And we can plot the marginalized probability density functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "Collapsed": "false",
        "id": "QwFJOBJ73Dk1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "corner.corner(samples[['m1_source_frame_Msun','m2_source_frame_Msun','redshift']].values,labels=['m1 (source)',\n",
        "                                                                                          'm2 (source)',\n",
        "                                                                                          'z']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "7x-iQAjXsMs1",
        "tags": []
      },
      "source": [
        "## Calculating credible intervals\n",
        "Let's see how we can use Bilby to calculate summary statistics for the posterior like the median and 90% credible level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj98kG5osMs2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import bilby\n",
        "\n",
        "# Make bilby more terse\n",
        "bilby.core.utils.log.setup_logger(log_level='WARNING')\n",
        "\n",
        "# calculate the detector frame chirp mass\n",
        "mchirp = ((samples['m1_detector_frame_Msun'] * samples['m2_detector_frame_Msun'])**(3./5))/\\\n",
        "         (samples['m1_detector_frame_Msun'] + samples['m2_detector_frame_Msun'])**(1./5)\n",
        "# initialize a SampleSummary object to describe the chirp mass posterior samples\n",
        "chirp_mass_samples_summary = bilby.core.utils.SamplesSummary(samples=mchirp, average='median')\n",
        "print('The median chirp mass = {} Msun'.format(chirp_mass_samples_summary.median))\n",
        "print('The 90% credible interval for the chirp mass is {} - {} Msun'.format(chirp_mass_samples_summary.lower_absolute_credible_interval,\n",
        "                                                                        chirp_mass_samples_summary.upper_absolute_credible_interval))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb-q5uxLsMs2"
      },
      "source": [
        "## Challenge question\n",
        "Calculate the posterior for the effective spin, which is the mass-weighted component of the binary spin aligned to the orbital angular momentum. It is given by Eqn. 3 of https://journals.aps.org/prx/pdf/10.1103/PhysRevX.9.011001. The z-component of each component spin is defined as $\\chi_{1z} = \\chi_{1}\\cos{\\theta_{1}}$. Then initialize a `SamplesSummary` object for the chi_eff posterior and calculate the mean and the lower and upper absolute credible interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "47Y-XEhqRZvG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}